/**
 * SQLite database initialization and management
 * Handles database creation, schema setup, and connection management
 */

import SQLite from 'better-sqlite3';
import fs from 'fs';
import os from 'os';
import path from 'path';
import { Logger } from '../core/interfaces.js';

/**
 * Silent no-op logger for when no logger is provided
 * Pattern: Null Object - avoids null checks throughout code
 */
const noOpLogger: Logger = {
  debug: () => {},
  info: () => {},
  warn: () => {},
  error: () => {},
  child: () => noOpLogger,
};

/**
 * SQLite database wrapper for Delegate task persistence.
 *
 * @remarks
 * Database location can be configured via environment variables:
 * - `DELEGATE_DATABASE_PATH`: Full absolute path to database file (e.g., `/tmp/test.db`)
 * - `DELEGATE_DATA_DIR`: Directory to store `delegate.db` (e.g., `~/.delegate`)
 * - Default: `~/.delegate/delegate.db`
 *
 * Security: Both environment variables are validated to prevent path traversal attacks.
 * Paths must be absolute and cannot contain `..` sequences.
 *
 * @example
 * ```typescript
 * // Use default path (~/.delegate/delegate.db)
 * const db = new Database();
 *
 * // Use custom path (for testing)
 * process.env.DELEGATE_DATABASE_PATH = '/tmp/test.db';
 * const testDb = new Database();
 * ```
 */
export class Database {
  private db: SQLite.Database;
  private readonly dbPath: string;
  private readonly logger: Logger;

  constructor(dbPath?: string, logger?: Logger) {
    this.dbPath = dbPath || this.getDefaultDbPath();
    this.logger = logger ?? noOpLogger;

    // Ensure data directory exists
    // Note: We intentionally keep sync operation in constructor
    // Async constructors are not supported in JS/TS
    // This runs once at startup, not in hot path
    const dataDir = path.dirname(this.dbPath);
    if (!fs.existsSync(dataDir)) {
      fs.mkdirSync(dataDir, { recursive: true });
    }

    // Initialize SQLite database
    this.db = new SQLite(this.dbPath);

    // SECURITY: Enable foreign key constraints (disabled by default in SQLite)
    // This prevents dependencies from referencing non-existent tasks
    this.db.pragma('foreign_keys = ON');

    // Configure for better performance and concurrency
    // Fall back to DELETE mode in test environments where WAL might fail
    try {
      this.db.pragma('journal_mode = WAL');
    } catch (error) {
      // WAL mode failed (common in CI environments), use DELETE mode
      this.logger.warn('WAL mode failed, falling back to DELETE mode', {
        error: error instanceof Error ? error.message : String(error),
      });
      this.db.pragma('journal_mode = DELETE');
    }
    this.db.pragma('synchronous = NORMAL');

    // Create tables if they don't exist
    this.createTables();
  }

  private getDefaultDbPath(): string {
    // Allow override via environment variables
    // SECURITY: Validate environment variables to prevent path traversal

    // DELEGATE_DATABASE_PATH: Full path to database file (used by tests)
    if (process.env.DELEGATE_DATABASE_PATH) {
      const dbPath = process.env.DELEGATE_DATABASE_PATH;

      // Validate path is absolute and doesn't contain traversal
      if (!path.isAbsolute(dbPath)) {
        throw new Error('DELEGATE_DATABASE_PATH must be an absolute path');
      }

      const normalized = path.normalize(dbPath);
      if (normalized.includes('..')) {
        throw new Error('DELEGATE_DATABASE_PATH must not contain path traversal sequences (..)');
      }

      return normalized;
    }

    // DELEGATE_DATA_DIR: Directory containing delegate.db
    if (process.env.DELEGATE_DATA_DIR) {
      const dataDir = process.env.DELEGATE_DATA_DIR;

      // Validate path is absolute and doesn't contain traversal
      if (!path.isAbsolute(dataDir)) {
        throw new Error('DELEGATE_DATA_DIR must be an absolute path');
      }

      const normalized = path.normalize(dataDir);
      if (normalized.includes('..')) {
        throw new Error('DELEGATE_DATA_DIR must not contain path traversal sequences (..)');
      }

      return path.join(normalized, 'delegate.db');
    }

    // Platform-specific defaults
    const homeDir = os.homedir();

    if (process.platform === 'win32') {
      // Windows: %APPDATA%/delegate
      const appData = process.env.APPDATA || path.join(homeDir, 'AppData', 'Roaming');
      return path.join(appData, 'delegate', 'delegate.db');
    } else {
      // Linux/Mac: ~/.delegate
      return path.join(homeDir, '.delegate', 'delegate.db');
    }
  }

  private createTables(): void {
    // SCHEMA MIGRATIONS: Only create migrations table here
    // All other tables are created through migrations (single source of truth)
    // Pattern: Version-based migrations with timestamps
    // Rationale: Enables safe schema evolution without data loss
    this.db.exec(`
      CREATE TABLE IF NOT EXISTS schema_migrations (
        version INTEGER PRIMARY KEY,
        applied_at INTEGER NOT NULL,
        description TEXT
      )
    `);

    // Get current schema version
    const currentVersion = this.getCurrentSchemaVersion();

    // Apply all pending migrations (schema lives in migrations)
    this.applyMigrations(currentVersion);
  }

  isOpen(): boolean {
    return this.db.open;
  }

  close(): void {
    if (this.db && this.db.open) {
      this.db.close();
    }
  }

  getTables(): string[] {
    const result = this.db
      .prepare(`
      SELECT name FROM sqlite_master 
      WHERE type='table' 
      ORDER BY name
    `)
      .all() as Array<{ name: string }>;

    return result.map((row) => row.name);
  }

  getJournalMode(): string {
    const result = this.db.prepare('PRAGMA journal_mode').get() as { journal_mode: string };
    return result.journal_mode;
  }

  getDatabase(): SQLite.Database {
    return this.db;
  }

  /**
   * Get current schema version from migrations table
   * Returns 0 if no migrations have been applied (fresh database)
   */
  private getCurrentSchemaVersion(): number {
    try {
      const result = this.db
        .prepare(`
        SELECT MAX(version) as version FROM schema_migrations
      `)
        .get() as { version: number | null };

      return result?.version || 0;
    } catch (error: unknown) {
      // Only return 0 if the table doesn't exist (fresh database)
      // Re-throw all other errors (permissions, corruption, connection issues)
      if (error instanceof Error && error.message.includes('no such table')) {
        return 0;
      }
      throw error;
    }
  }

  /**
   * Apply migrations incrementally from current version to latest
   * Pattern: Version-based migrations with idempotent operations
   * Rationale: Safe incremental upgrades without data loss
   */
  private applyMigrations(currentVersion: number): void {
    const migrations = this.getMigrations();

    // Apply migrations in order
    for (const migration of migrations) {
      if (migration.version > currentVersion) {
        this.logger.info('Applying database migration', {
          version: migration.version,
          description: migration.description,
        });

        // Run migration in transaction for safety
        const applyMigration = this.db.transaction(() => {
          // Execute migration SQL
          migration.up(this.db);

          // Record migration as applied
          this.db
            .prepare(`
            INSERT INTO schema_migrations (version, applied_at, description)
            VALUES (?, ?, ?)
          `)
            .run(migration.version, Date.now(), migration.description);
        });

        applyMigration();
        this.logger.info('Database migration applied successfully', {
          version: migration.version,
        });
      }
    }
  }

  /**
   * Define all schema migrations
   * Add new migrations here with incrementing version numbers
   *
   * ARCHITECTURE: Migrations are the single source of truth for schema
   * - Fresh databases: All migrations run in order
   * - Existing databases: Only new migrations run (skips already applied)
   * - Uses IF NOT EXISTS for idempotency (safe if migration runs twice)
   */
  private getMigrations(): Array<{
    version: number;
    description: string;
    up: (db: SQLite.Database) => void;
  }> {
    return [
      {
        version: 1,
        description: 'Baseline schema with tasks, dependencies, and output tables',
        up: (db) => {
          // Tasks table - core task data
          db.exec(`
            CREATE TABLE IF NOT EXISTS tasks (
              id TEXT PRIMARY KEY,
              prompt TEXT NOT NULL,
              status TEXT NOT NULL,
              priority TEXT NOT NULL,
              working_directory TEXT,
              timeout INTEGER,
              max_output_buffer INTEGER,
              parent_task_id TEXT,
              retry_count INTEGER,
              retry_of TEXT,
              created_at INTEGER NOT NULL,
              started_at INTEGER,
              completed_at INTEGER,
              worker_id TEXT,
              exit_code INTEGER,
              dependencies TEXT
            )
          `);

          // Task output table - stdout/stderr capture
          db.exec(`
            CREATE TABLE IF NOT EXISTS task_output (
              task_id TEXT PRIMARY KEY,
              stdout TEXT,
              stderr TEXT,
              total_size INTEGER,
              file_path TEXT,
              FOREIGN KEY (task_id) REFERENCES tasks(id) ON DELETE CASCADE
            )
          `);

          // Task dependencies table - DAG for dependency tracking
          // Pattern: Normalized dependency tracking with resolution states
          // Rationale: Enables efficient cycle detection, dependency queries, and state tracking
          db.exec(`
            CREATE TABLE IF NOT EXISTS task_dependencies (
              id INTEGER PRIMARY KEY AUTOINCREMENT,
              task_id TEXT NOT NULL,
              depends_on_task_id TEXT NOT NULL,
              created_at INTEGER NOT NULL,
              resolved_at INTEGER,
              resolution TEXT NOT NULL DEFAULT 'pending',
              FOREIGN KEY (task_id) REFERENCES tasks(id) ON DELETE CASCADE,
              FOREIGN KEY (depends_on_task_id) REFERENCES tasks(id) ON DELETE CASCADE,
              UNIQUE(task_id, depends_on_task_id)
            )
          `);

          // Performance indexes
          db.exec(`
            CREATE INDEX IF NOT EXISTS idx_tasks_status ON tasks(status);
            CREATE INDEX IF NOT EXISTS idx_tasks_priority ON tasks(priority);
            CREATE INDEX IF NOT EXISTS idx_tasks_created_at ON tasks(created_at);
            CREATE INDEX IF NOT EXISTS idx_task_dependencies_task_id ON task_dependencies(task_id);
            CREATE INDEX IF NOT EXISTS idx_task_dependencies_depends_on ON task_dependencies(depends_on_task_id);
            CREATE INDEX IF NOT EXISTS idx_task_dependencies_resolution ON task_dependencies(resolution);
            CREATE INDEX IF NOT EXISTS idx_task_dependencies_blocked ON task_dependencies(task_id, resolution);
            CREATE INDEX IF NOT EXISTS idx_task_dependencies_depends_on_resolution ON task_dependencies(depends_on_task_id, resolution);
          `);
        },
      },
      {
        version: 2,
        description: 'Add CHECK constraint on resolution column for defense-in-depth',
        up: (db) => {
          // SQLite doesn't support adding CHECK constraints to existing columns
          // So we recreate the table with the constraint
          // Pattern: Safe table migration with data preservation
          db.exec(`
            -- Create new table with CHECK constraint
            CREATE TABLE task_dependencies_new (
              id INTEGER PRIMARY KEY AUTOINCREMENT,
              task_id TEXT NOT NULL,
              depends_on_task_id TEXT NOT NULL,
              created_at INTEGER NOT NULL,
              resolved_at INTEGER,
              resolution TEXT NOT NULL DEFAULT 'pending'
                CHECK (resolution IN ('pending', 'completed', 'failed', 'cancelled')),
              FOREIGN KEY (task_id) REFERENCES tasks(id) ON DELETE CASCADE,
              FOREIGN KEY (depends_on_task_id) REFERENCES tasks(id) ON DELETE CASCADE,
              UNIQUE(task_id, depends_on_task_id)
            );

            -- Copy existing data (all existing values should be valid)
            INSERT INTO task_dependencies_new
              SELECT * FROM task_dependencies;

            -- Drop old table
            DROP TABLE task_dependencies;

            -- Rename new table
            ALTER TABLE task_dependencies_new RENAME TO task_dependencies;

            -- Recreate indexes (indexes don't survive table rename)
            CREATE INDEX IF NOT EXISTS idx_task_dependencies_task_id ON task_dependencies(task_id);
            CREATE INDEX IF NOT EXISTS idx_task_dependencies_depends_on ON task_dependencies(depends_on_task_id);
            CREATE INDEX IF NOT EXISTS idx_task_dependencies_resolution ON task_dependencies(resolution);
            CREATE INDEX IF NOT EXISTS idx_task_dependencies_blocked ON task_dependencies(task_id, resolution);
            CREATE INDEX IF NOT EXISTS idx_task_dependencies_depends_on_resolution ON task_dependencies(depends_on_task_id, resolution);
          `);
        },
      },
      {
        version: 3,
        description: 'Add CHECK constraints on status and priority columns for defense-in-depth',
        up: (db) => {
          // SQLite doesn't support adding CHECK constraints to existing columns
          // So we recreate the table with the constraints
          // Pattern: Safe table migration with data preservation
          db.exec(`
            -- Create new table with CHECK constraints
            CREATE TABLE tasks_new (
              id TEXT PRIMARY KEY,
              prompt TEXT NOT NULL,
              status TEXT NOT NULL CHECK (status IN ('queued', 'running', 'completed', 'failed', 'cancelled')),
              priority TEXT NOT NULL CHECK (priority IN ('P0', 'P1', 'P2')),
              working_directory TEXT,
              timeout INTEGER,
              max_output_buffer INTEGER,
              parent_task_id TEXT,
              retry_count INTEGER,
              retry_of TEXT,
              created_at INTEGER NOT NULL,
              started_at INTEGER,
              completed_at INTEGER,
              worker_id TEXT,
              exit_code INTEGER,
              dependencies TEXT
            );

            -- Copy existing data (all existing values should be valid)
            INSERT INTO tasks_new SELECT * FROM tasks;

            -- Drop old table
            DROP TABLE tasks;

            -- Rename new table
            ALTER TABLE tasks_new RENAME TO tasks;

            -- Recreate indexes (indexes don't survive table rename)
            CREATE INDEX IF NOT EXISTS idx_tasks_status ON tasks(status);
            CREATE INDEX IF NOT EXISTS idx_tasks_priority ON tasks(priority);
            CREATE INDEX IF NOT EXISTS idx_tasks_created_at ON tasks(created_at);
          `);
        },
      },
      {
        version: 4,
        description: 'Add schedules and schedule_executions tables for task scheduling',
        up: (db) => {
          // Schedules table - stores schedule definitions
          // ARCHITECTURE: Supports both cron-based recurring and one-time schedules
          // Pattern: task_template stored as JSON for DelegateRequest serialization
          db.exec(`
            CREATE TABLE IF NOT EXISTS schedules (
              id TEXT PRIMARY KEY,
              task_template TEXT NOT NULL,
              schedule_type TEXT NOT NULL CHECK (schedule_type IN ('cron', 'one_time')),
              cron_expression TEXT,
              scheduled_at INTEGER,
              timezone TEXT NOT NULL DEFAULT 'UTC',
              missed_run_policy TEXT NOT NULL DEFAULT 'skip' CHECK (missed_run_policy IN ('skip', 'catchup', 'fail')),
              status TEXT NOT NULL DEFAULT 'active' CHECK (status IN ('active', 'paused', 'completed', 'cancelled', 'expired')),
              max_runs INTEGER CHECK (max_runs > 0),
              run_count INTEGER NOT NULL DEFAULT 0 CHECK (run_count >= 0),
              last_run_at INTEGER,
              next_run_at INTEGER,
              expires_at INTEGER,
              created_at INTEGER NOT NULL,
              updated_at INTEGER NOT NULL
            )
          `);

          // Schedule executions table - audit trail of schedule triggers
          // ARCHITECTURE: Tracks each execution attempt for debugging and monitoring
          // Pattern: References schedule and optionally created task
          db.exec(`
            CREATE TABLE IF NOT EXISTS schedule_executions (
              id INTEGER PRIMARY KEY AUTOINCREMENT,
              schedule_id TEXT NOT NULL,
              task_id TEXT,
              scheduled_for INTEGER NOT NULL,
              executed_at INTEGER,
              status TEXT NOT NULL CHECK (status IN ('pending', 'triggered', 'completed', 'failed', 'missed', 'skipped')),
              error_message TEXT,
              created_at INTEGER NOT NULL,
              FOREIGN KEY (schedule_id) REFERENCES schedules(id) ON DELETE CASCADE,
              FOREIGN KEY (task_id) REFERENCES tasks(id) ON DELETE SET NULL
            )
          `);

          // Performance indexes for schedule queries
          db.exec(`
            CREATE INDEX IF NOT EXISTS idx_schedules_status ON schedules(status);
            CREATE INDEX IF NOT EXISTS idx_schedules_next_run ON schedules(next_run_at);
            CREATE INDEX IF NOT EXISTS idx_schedules_due ON schedules(status, next_run_at);
            CREATE INDEX IF NOT EXISTS idx_schedule_executions_schedule ON schedule_executions(schedule_id);
            CREATE INDEX IF NOT EXISTS idx_schedule_executions_schedule_time ON schedule_executions(schedule_id, scheduled_for DESC);
            CREATE INDEX IF NOT EXISTS idx_schedule_executions_status ON schedule_executions(status);
          `);
        },
      },
      {
        version: 5,
        description: 'Add task_checkpoints table and after_schedule_id column for v0.4.0',
        up: (db) => {
          // Task checkpoints table for "smart retry" resumption
          // ARCHITECTURE: Captures task state snapshots for enriched retry prompts
          db.exec(`
            CREATE TABLE IF NOT EXISTS task_checkpoints (
              id INTEGER PRIMARY KEY AUTOINCREMENT,
              task_id TEXT NOT NULL,
              checkpoint_type TEXT NOT NULL CHECK (checkpoint_type IN ('completed', 'failed', 'cancelled')),
              output_summary TEXT,
              error_summary TEXT,
              git_branch TEXT,
              git_commit_sha TEXT,
              git_dirty_files TEXT,
              context_note TEXT,
              created_at INTEGER NOT NULL,
              FOREIGN KEY (task_id) REFERENCES tasks(id) ON DELETE CASCADE
            )
          `);

          // Performance indexes for checkpoint queries
          db.exec(`
            CREATE INDEX IF NOT EXISTS idx_task_checkpoints_task_id ON task_checkpoints(task_id);
            CREATE INDEX IF NOT EXISTS idx_task_checkpoints_task_time ON task_checkpoints(task_id, created_at DESC);
          `);

          // Add after_schedule_id column for schedule chaining
          db.exec(`
            ALTER TABLE schedules ADD COLUMN after_schedule_id TEXT
          `);
        },
      },
      {
        version: 6,
        description: 'Add continue_from column for session continuation through dependency chains',
        up: (db) => {
          db.exec(`ALTER TABLE tasks ADD COLUMN continue_from TEXT`);
        },
      },
    ];
  }

  /**
   * Get current schema version (public method for monitoring/debugging)
   */
  getSchemaVersion(): number {
    return this.getCurrentSchemaVersion();
  }
}
